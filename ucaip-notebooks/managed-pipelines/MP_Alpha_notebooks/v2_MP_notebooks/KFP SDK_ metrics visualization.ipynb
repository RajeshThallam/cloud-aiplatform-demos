{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUkyIjOxW7bi"
   },
   "source": [
    "# Managed Pipelines Experimental: Metrics visualization with the KFP SDK\n",
    "\n",
    "This notebook shows how to visualize ROC curves and Confusion Matrices on [Managed Pipelines Experimental](https://docs.google.com/document/d/1JXtowHwppgyghnj1N1CT73hwD1caKtWkLcm2_0qGBoI/edit?ts=5f90dcea#heading=h.p4rp2vtz67w2), using the [Kubeflow Pipelines (KFP) SDK](https://www.kubeflow.org/docs/pipelines/) \n",
    "\n",
    "In the process, it shows how to construct *function-based components* — pipeline components defined from Python function definitions— and how to specify a pipeline using those components, then launch a pipeline run from the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWACue6PW7bk"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Before you run this notebook, ensure that your Google Cloud user account and project are granted access to the Managed Pipelines Experimental. To be granted access to the Managed Pipelines Experimental, fill out this [form](http://go/cloud-mlpipelines-signup) and let your account representative know you have requested access. \n",
    "\n",
    "This notebook is intended to be run on either one of:\n",
    "* [AI Platform Notebooks](https://cloud.google.com/ai-platform-notebooks). See the \"AI Platform Notebooks\" section in the Experimental [User Guide](https://docs.google.com/document/d/1JXtowHwppgyghnj1N1CT73hwD1caKtWkLcm2_0qGBoI/edit?usp=sharing) for more detail on creating a notebook server instance.\n",
    "* [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb)\n",
    "\n",
    "\n",
    "**To run this notebook on AI Platform Notebooks**, click on the **File** menu, then select \"Download .ipynb\".  Then, upload that notebook from your local machine to AI Platform Notebooks. (In the AI Platform Notebooks left panel, look for an icon of an arrow pointing up, to upload).\n",
    "\n",
    "We'll first install some libraries and set up some variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAaCPLjgiJrO"
   },
   "source": [
    "Set `gcloud` to use your project.  **Edit the following cell before running it**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pD5jOcSURdcU"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'your-project-id'  # <---CHANGE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkWdxe4TXRHk"
   },
   "outputs": [],
   "source": [
    "!gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gckGHdW9iPrq"
   },
   "source": [
    "If you're running this notebook on colab, authenticate with your user account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZQA0KrfXCvU"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaqJjbmk6o0o"
   },
   "source": [
    "-----------------\n",
    "\n",
    "**If you're on AI Platform Notebooks**, authenticate with Google Cloud before running the next section, by running\n",
    "```sh\n",
    "gcloud auth login\n",
    "```\n",
    "**in the Terminal window** (which you can open via **File** > **New** in the menu). You only need to do this once per notebook instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOpZ41iBW7bl"
   },
   "source": [
    "### Install the KFP SDK and AI Platform Pipelines client library\n",
    "\n",
    "For Managed Pipelines Experimental, you'll need to download special versions of the KFP SDK and the AI Platform client library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJGkLRUpRmso"
   },
   "outputs": [],
   "source": [
    "!gsutil cp gs://cloud-aiplatform-pipelines/releases/latest/kfp-1.5.0rc5.tar.gz .\n",
    "!gsutil cp gs://cloud-aiplatform-pipelines/releases/latest/aiplatform_pipelines_client-0.1.0.caip20210415-py3-none-any.whl .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpdfRA4vW7bq"
   },
   "source": [
    "Then, install the libraries and restart the kernel as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmUZzSv6YA9-"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "  USER_FLAG = ''\n",
    "else:\n",
    "  USER_FLAG = '--user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGdU0lEfVwM-"
   },
   "outputs": [],
   "source": [
    "!python3 -m pip install {USER_FLAG} kfp-1.5.0rc5.tar.gz --upgrade\n",
    "!python3 -m pip install {USER_FLAG} aiplatform_pipelines_client-0.1.0.caip20210415-py3-none-any.whl  --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IKZcgZnX3j6"
   },
   "outputs": [],
   "source": [
    "if not 'google.colab' in sys.modules:\n",
    "  # Automatically restart kernel after installs\n",
    "  import IPython\n",
    "  app = IPython.Application.instance()\n",
    "  app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mqs-ZFuW7bx"
   },
   "source": [
    "The KFP version should be >= 1.5.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4uvTyimMYOr"
   },
   "outputs": [],
   "source": [
    "# Check the KFP version\n",
    "!python3 -c \"import kfp; print('KFP version: {}'.format(kfp.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tskC13YxW7b3"
   },
   "source": [
    "### Set some variables and do some imports\n",
    "\n",
    "**Before you run the next cell**, **edit it** to set variables for your project.  See the \"Before you begin\" section of the User Guide for information on creating your API key.  For `BUCKET_NAME`, enter the name of a Cloud Storage (GCS) bucket in your project.  Don't include the `gs://` prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHsVifdTW7b4"
   },
   "outputs": [],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "\n",
    "# Required Parameters\n",
    "USER = 'YOUR_USER_NAME' # <---CHANGE THIS\n",
    "BUCKET_NAME = 'YOUR_BUCKET_NAME'  # <---CHANGE THIS\n",
    "PIPELINE_ROOT = 'gs://{}/pipeline_root/{}'.format(BUCKET_NAME, USER)\n",
    "\n",
    "PROJECT_ID = 'YOUR_PROJECT_ID'  # <---CHANGE THIS\n",
    "REGION = 'us-central1'\n",
    "API_KEY = 'YOUR_API_KEY'  # <---CHANGE THIS\n",
    "\n",
    "print('PIPELINE_ROOT: {}'.format(PIPELINE_ROOT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37bfm2cwYAjb"
   },
   "source": [
    "Import what's needed for building lightweight Python-function-based components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmMeVQ-fUEUM"
   },
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (\n",
    "    component,\n",
    "    InputPath,\n",
    "    OutputPath,\n",
    "    InputArtifact,\n",
    "    OutputArtifact,\n",
    "    Artifact,\n",
    "    Dataset,\n",
    "    Model,\n",
    "    ClassificationMetrics,\n",
    "    Metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QW9EmIXmYLa6"
   },
   "source": [
    "## Define Pipeline components\n",
    "\n",
    "We'll define some function-based components that use SKLearn to train some classifiers and produce evaluations that can be visualized. \n",
    "\n",
    "We're building Python-function-based components.   \n",
    "Note the use of the `@component()` decorator in the definitions below.  We can optionally set a list of packages for the component to install; the base image to use (the default is a Python3.7 image); and the name of a component yaml file to generate, so that the component definition can be shared and reused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilCtAGi-W_gt"
   },
   "source": [
    "The first component shows how to visualize an *ROC curve*. \n",
    "Note that the function definition includes an input called `metrics`, of type `OutputArtifact(ClassificationMetrics)`. This component will output a `ClassificationMetrics` artifact, and we will be able to visualize the metrics in the Pipelines UI in the Cloud Console.\n",
    "\n",
    "To do this, we're using the artifact's `log_roc_curve()` method. This method takes as input arrays with the false positive rates, true positive rates, and thresholds, as [generated by the `sklearn.metrics.roc_curve` function](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html).\n",
    "\n",
    "When you evaluate the cell below, a task factory function called `wine_classification` will be created, that we will use to construct our pipeline definition.  In addition, a component `.yaml` file will be created, which can be shared and loaded via file or URL to create the same task function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZ_kXbhCUEUN"
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=['sklearn'],\n",
    "    base_image='python:3.9',\n",
    "    output_component_file='wine_classif_component.yaml'\n",
    ")\n",
    "def wine_classification(metrics: OutputArtifact(ClassificationMetrics)):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import roc_curve\n",
    "    from sklearn.datasets import load_wine\n",
    "    from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "\n",
    "    X, y = load_wine(return_X_y=True)\n",
    "    # Binary classification problem for label 1.\n",
    "    y = y == 1\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_scores = cross_val_predict(rfc, X_train, y_train, cv=3, method='predict_proba')\n",
    "    y_predict = cross_val_predict(rfc, X_train, y_train, cv=3, method='predict')\n",
    "    fpr, tpr, thresholds = roc_curve(y_true=y_train, y_score=y_scores[:,1], pos_label=True)\n",
    "    metrics.get().log_roc_curve(fpr, tpr, thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYoi5Etr3EJM"
   },
   "source": [
    "The second component shows how to visualize a *confusion matrix*.\n",
    "\n",
    "As with the previous component, we're creating a `metrics` output artifact.  We're then using the artifact's `log_confusion_matrix` method to visualize the confusion matrix results, as generated by the [sklearn.metrics.confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ZCLrE7IUEUN"
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=['sklearn'],\n",
    "    base_image='python:3.9'\n",
    "    )\n",
    "def iris_sgdclassifier(test_samples_fraction: float, metrics: OutputArtifact(ClassificationMetrics)):\n",
    "    from sklearn import datasets, model_selection\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    iris_dataset = datasets.load_iris()\n",
    "    train_x, test_x, train_y, test_y = model_selection.train_test_split(\n",
    "        iris_dataset['data'], iris_dataset['target'], test_size=test_samples_fraction)\n",
    "\n",
    "    \n",
    "    classifier = SGDClassifier()\n",
    "    classifier.fit(train_x, train_y)\n",
    "    predictions = model_selection.cross_val_predict(classifier, train_x, train_y, cv=3)\n",
    "    metrics.get().log_confusion_matrix(\n",
    "        ['Setosa', 'Versicolour', 'Virginica'],\n",
    "        confusion_matrix(train_y, predictions).tolist() # .tolist() to convert np array to list.\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmKIkUCoZeAu"
   },
   "source": [
    "## Define a pipeline that uses the new components\n",
    "\n",
    "Next, we'll define a simple pipeline that uses the two components that we defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "289jqF_XUEUO"
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    # Default pipeline root. You can override it when submitting the pipeline.\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    # A name for the pipeline. \n",
    "    name='metrics-pipeline-v2')\n",
    "def pipeline():\n",
    "  wine_classification_op = wine_classification()\n",
    "  iris_sgdclassifier_op = iris_sgdclassifier(test_samples_fraction=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "du8zTAm0zBtb"
   },
   "source": [
    "## Compile and run the pipeline\n",
    "\n",
    "We'll compile the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLcgbrL6ygTM"
   },
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler\n",
    "from aiplatform.pipelines import client  \n",
    "\n",
    "compiler.Compiler().compile(pipeline_func=pipeline,                                                     \n",
    "                            package_path='metrics_pipeline.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qN1esMEFzGMF"
   },
   "source": [
    "... and run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LneSNBc9ygDM"
   },
   "outputs": [],
   "source": [
    "api_client = client.Client(\n",
    "  project_id=PROJECT_ID,\n",
    "  region='us-central1',\n",
    "  api_key=API_KEY)\n",
    "\n",
    "response = api_client.create_run_from_job_spec(\n",
    "  job_spec_path='metrics_pipeline.json',\n",
    "  pipeline_root=PIPELINE_ROOT,  # Override if needed.\n",
    "  parameter_values={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBtfYYt9zJP4"
   },
   "source": [
    "You can click the generated link above to view the pipeline run in the Cloud Console. When the pipeline steps finish executing, you can view the generated metrics visualizations by clicking on the metrics artifacts.\n",
    "\n",
    "The ROC curve should look as follows:\n",
    "\n",
    "<a href=\"https://storage.googleapis.com/amy-jo/images/mp/roc_curve.png\" target=\"_blank\"><img src=\"https://storage.googleapis.com/amy-jo/images/mp/roc_curve.png\" width=\"90%\"/></a>\n",
    "\n",
    "... and the confusion matrix should look like this:\n",
    "\n",
    "<a href=\"https://storage.googleapis.com/amy-jo/images/mp/confusion_matrix.png\" target=\"_blank\"><img src=\"https://storage.googleapis.com/amy-jo/images/mp/confusion_matrix.png\" width=\"90%\"/></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89fYarRLW7cN"
   },
   "source": [
    "-----------------------------\n",
    "Copyright 2021 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KFP SDK: metrics visualization.ipynb",
   "provenance": [
    {
     "file_id": "1Sas6rk0w2puxnaJJMPVBuIk1womgKrzf",
     "timestamp": 1618883500990
    },
    {
     "file_id": "1l5YhFRekgxkIJunM4ijS1oA67QGMH30d",
     "timestamp": 1618545841842
    },
    {
     "file_id": "1C9orZkxeVafv6hdDZok5vsO4HlpDcWy2",
     "timestamp": 1618545303549
    }
   ],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
