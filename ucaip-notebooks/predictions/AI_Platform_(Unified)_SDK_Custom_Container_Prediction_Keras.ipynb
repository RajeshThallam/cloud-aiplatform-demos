{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/ai-platform-samples/blob/master/ai-platform-unified/notebooks/unofficial/AI_Platform_(Unified)_SDK_Custom_Container_Prediction_Keras.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This tutorial walks through building a custom container to serve a Keras model on AI Platform Predictions. You will use the FastAPI Python web server framework to create a prediction and health endpoint.\n",
    "You will also cover incorporating a pre-processor from training into your online serving.\n",
    "\n",
    "This tutorial shows how to deploy a trained Keras model to AI Platform and serve predictions on AI Platform Predictions using a [custom container](https://cloud.google.com/ai-platform-unified/docs/predictions/use-custom-container). This lets you customize how AI Platform responds to each prediction request.\n",
    "\n",
    "In this example, you will use a custom container with a preprocessing step that scales prediction input, and a postprocess step to convert prediction output from [softmax](https://developers.google.com/machine-learning/glossary/#s) probability outputs to label strings.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "This tutorial uses R.A. Fisher's Iris dataset, a small dataset that is popular for trying out machine learning techniques. Each instance has four numerical features, which are different measurements of a flower, and a target label that\n",
    "marks it as one of three types of iris: Iris setosa, Iris versicolour, or Iris virginica.\n",
    "\n",
    "This tutorial uses [the copy of the Iris dataset included in the\n",
    "scikit-learn library](https://scikit-learn.org/stable/datasets/index.html#iris-dataset).\n",
    "\n",
    "### Objective\n",
    "\n",
    "The goal is to train a model that uses a flower's measurements as input to predict what type of iris it is.\n",
    "\n",
    "The tutorial walks through several steps:\n",
    "\n",
    "- Training a simple Keras model locally (in this notebook)\n",
    "- Save the model and its serialized pre-processor and post-processor\n",
    "- Build a FastAPI server to handle predictions and health checks\n",
    "- Build a custom container with model artifacts\n",
    "- Upload and deploy custom container to AI Platform Prediction\n",
    "- Serve prediction requests from that deployment\n",
    "\n",
    "This tutorial focuses more on deploying this model with AI Platform than on\n",
    "the design of the model itself.\n",
    "\n",
    "### Costs \n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* AI Platform (Unified)\n",
    "\n",
    "Learn about [AI Platform (Unified)\n",
    "pricing](https://cloud.google.com/ai-platform-unified/pricing), and use the [Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ze4-nDLfK4pw"
   },
   "source": [
    "### Set up your local development environment\n",
    "\n",
    "**If you are using Colab or AI Platform Notebooks**, your environment already meets\n",
    "all the requirements to run this notebook. You can skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCuSR8GkAgzl"
   },
   "source": [
    "**Otherwise**, make sure your environment meets this notebook's requirements.\n",
    "You need the following:\n",
    "\n",
    "* Docker\n",
    "* Git\n",
    "* Google Cloud SDK (gcloud)\n",
    "* Python 3\n",
    "* virtualenv\n",
    "* Jupyter notebook running in a virtual environment with Python 3\n",
    "\n",
    "The Google Cloud guide to [Setting up a Python development\n",
    "environment](https://cloud.google.com/python/setup) and the [Jupyter\n",
    "installation guide](https://jupyter.org/install) provide detailed instructions\n",
    "for meeting these requirements. The following steps provide a condensed set of\n",
    "instructions:\n",
    "\n",
    "1. [Install and initialize the Cloud SDK.](https://cloud.google.com/sdk/docs/)\n",
    "\n",
    "1. [Install Python 3.](https://cloud.google.com/python/setup#installing_python)\n",
    "\n",
    "1. [Install\n",
    "   virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv)\n",
    "   and create a virtual environment that uses Python 3. Activate the virtual environment.\n",
    "\n",
    "1. To install Jupyter, run `pip install jupyter` on the\n",
    "command-line in a terminal shell.\n",
    "\n",
    "1. To launch Jupyter, run `jupyter notebook` on the command-line in a terminal shell.\n",
    "\n",
    "1. Open this notebook in the Jupyter Notebook Dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "### Install additional packages\n",
    "\n",
    "Install additional package dependencies not installed in your notebook environment, such as Tensorflow, NumPy, Scikit-learn, FastAPI, Uvicorn, and joblib. Use the latest major GA version of each package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "747f59abb3a5",
    "outputId": "78c4a18b-a9e0-4046-cdb9-e31ab8ce8eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "joblib~=1.0\n",
    "numpy~=1.20\n",
    "scikit-learn~=0.24\n",
    "tensorflow>=1.15\n",
    "google-cloud-storage>=1.26.0,<2.0.0dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyy5Lbnzg5fi"
   },
   "outputs": [],
   "source": [
    "# Required in Docker serving container\n",
    "%pip install -U --user -r requirements.txt\n",
    "\n",
    "# For local FastAPI development and running\n",
    "%pip install -U --user \"uvicorn[standard]>=0.12.0,<0.14.0\" fastapi~=0.63\n",
    "\n",
    "# AI Platform (Unified) SDK\n",
    "%pip install -U --user google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhq5zEbGg0XX"
   },
   "source": [
    "### Restart the kernel\n",
    "\n",
    "After you install the additional packages, you need to restart the notebook kernel so it can find the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EzrelQZ22IZj"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWEdiXsJg0XY"
   },
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "### Set up your Google Cloud project\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
    "\n",
    "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
    "\n",
    "1. [Enable the AI Platform (Unified) API and Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component).\n",
    "\n",
    "1. If you are running this notebook locally, you will need to install the [Cloud SDK](https://cloud.google.com/sdk).\n",
    "\n",
    "1. Enter your project ID in the cell below. Then run the cell to make sure the\n",
    "Cloud SDK uses the right project for all the commands in this notebook.\n",
    "\n",
    "**Note**: Jupyter runs lines prefixed with `!` or `%` as shell commands, and it interpolates Python variables with `$` or `{}` into these commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "#### Set your project ID\n",
    "\n",
    "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oM1iC_MfAts1",
    "outputId": "49f06f06-12c3-4090-fe46-f91fe62a1378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: rthallam-demo-project\n"
     ]
    }
   ],
   "source": [
    "# Get your Google Cloud project ID from gcloud\n",
    "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "\n",
    "try:\n",
    "    PROJECT_ID = shell_output[0]\n",
    "except IndexError:\n",
    "    PROJECT_ID = None\n",
    "\n",
    "print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJYoRfYng0XZ"
   },
   "source": [
    "Otherwise, set your project ID here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "riG_qUokg0XZ"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
    "    PROJECT_ID = \"rthallam-demo-project\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dr--iN2kAylZ"
   },
   "source": [
    "### Authenticate your Google Cloud account\n",
    "\n",
    "**If you are using AI Platform Notebooks**, your environment is already\n",
    "authenticated. Skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBCra4QMA2wR"
   },
   "source": [
    "**If you are using Colab**, run the cell below and follow the instructions\n",
    "when prompted to authenticate your account via oAuth.\n",
    "\n",
    "**Otherwise**, follow these steps:\n",
    "\n",
    "1. In the Cloud Console, go to the [**Create service account key**\n",
    "   page](https://console.cloud.google.com/apis/credentials/serviceaccountkey).\n",
    "\n",
    "2. Click **Create service account**.\n",
    "\n",
    "3. In the **Service account name** field, enter a name, and\n",
    "   click **Create**.\n",
    "\n",
    "4. In the **Grant this service account access to project** section, click the **Role** drop-down list. Type \"AI Platform\"\n",
    "into the filter box, and select\n",
    "   **AI Platform Administrator**. Type \"Storage Object Admin\" into the filter box, and select **Storage Object Admin**.\n",
    "\n",
    "5. Click *Create*. A JSON file that contains your key downloads to your\n",
    "local environment.\n",
    "\n",
    "6. Enter the path to your service account key as the\n",
    "`GOOGLE_APPLICATION_CREDENTIALS` variable in the cell below and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "# If on AI Platform, then don't execute this code\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\"):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\") and not os.getenv(\n",
    "        \"GOOGLE_APPLICATION_CREDENTIALS\"\n",
    "    ):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoEqT2Y4DJmf"
   },
   "source": [
    "### Configure project and resource names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "MODEL_ARTIFACT_DIR = \"custom-container-prediction-model\"  # @param {type:\"string\"}\n",
    "REPOSITORY = \"custom-container-prediction\"  # @param {type:\"string\"}\n",
    "IMAGE = \"keras-fastapi-server\"  # @param {type:\"string\"}\n",
    "MODEL_DISPLAY_NAME = \"keras-custom-container\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ca1a915d641d"
   },
   "source": [
    "`REGION` - Used for operations\n",
    "throughout the rest of this notebook. Make sure to [choose a region where Cloud\n",
    "AI Platform services are\n",
    "available](https://cloud.google.com/ai-platform-unified/docs/general/locations#feature-availability). You may\n",
    "not use a Multi-Regional Storage bucket for training with AI Platform.\n",
    "\n",
    "`MODEL_ARTIFACT_DIR` - Folder directory path to your model artifacts within a Cloud Storage bucket, for example: \"my-models/fraud-detection/trial-4\"\n",
    "\n",
    "`REPOSITORY` - Name of the Artifact Repository to create or use.\n",
    "\n",
    "`IMAGE` - Name of the container image that will be pushed.\n",
    "\n",
    "`MODEL_DISPLAY_NAME` - Display name of AI Platform (Unified) Model resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62f861b68b50"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "To update your model artifacts without re-building the container, you must upload your model\n",
    "artifacts and any custom code to Cloud Storage.\n",
    "\n",
    "Set the name of your Cloud Storage bucket below. It must be unique across all\n",
    "Cloud Storage buckets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9724b00aeead"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"gs://cloud-ai-platform-2f444b6a-a742-444b-b91a-c7519f51bd77\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58cb4f5895f0"
   },
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2d2208676cee"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c664a5abc11a"
   },
   "source": [
    "Finally, validate access to your Cloud Storage bucket by examining its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2c1b1c29f5f6"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c2d091d9e73"
   },
   "source": [
    "## Write your pre-processor\n",
    "Scaling training data so each numerical feature column has a mean of 0 and a standard deviation of 1 [can improve your model](https://developers.google.com/machine-learning/crash-course/representation/cleaning-data).\n",
    "\n",
    "Create `preprocess.py`, which contains a class to do this scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/cloud-aiplatform-demos/ucaip-notebooks/predictions\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6e74556ea0b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘app’: File exists\n"
     ]
    }
   ],
   "source": [
    "%mkdir app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58d843d21fa8",
    "outputId": "47b72480-ea4e-430c-a0ea-17df31aed9a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/preprocess.py\n",
    "import numpy as np\n",
    "\n",
    "class MySimpleScaler(object):\n",
    "  def __init__(self):\n",
    "    self._means = None\n",
    "    self._stds = None\n",
    "\n",
    "  def preprocess(self, data):\n",
    "    if self._means is None: # during training only\n",
    "      self._means = np.mean(data, axis=0)\n",
    "\n",
    "    if self._stds is None: # during training only\n",
    "      self._stds = np.std(data, axis=0)\n",
    "      if not self._stds.all():\n",
    "        raise ValueError('At least one column has standard deviation of 0.')\n",
    "\n",
    "    return (data - self._means) / self._stds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLnSJWJgDaJN"
   },
   "source": [
    "Notice that an instance of `MySimpleScaler` saves the means and standard deviations of each feature column on first use. Then it uses these summary statistics to scale data it encounters afterward.\n",
    "\n",
    "This lets you store characteristics of the training distribution and use them for identical preprocessing at prediction time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4b816cd52f4b"
   },
   "source": [
    "## Train and store model with pre-processor\n",
    "Next, use `preprocess.MySimpleScaler` to preprocess the iris data, then train a model using scikit-learn.\n",
    "\n",
    "At the end, export your trained model as a joblib (`.joblib`) file and export your `MySimpleScaler` instance as a pickle (`.pkl`) file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/cloud-aiplatform-demos/ucaip-notebooks/predictions\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43e47249f736",
    "outputId": "1f1615c1-70de-4203-e36c-44c83f423735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/cloud-aiplatform-demos/ucaip-notebooks/predictions/app\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 1s 1ms/step - loss: 0.8984 - accuracy: 0.6600\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.8400\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3001 - accuracy: 0.9067\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2342 - accuracy: 0.9200\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.9267\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1567 - accuracy: 0.9467\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9533\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1142 - accuracy: 0.9600\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.9600\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0984 - accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "%cd app/\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import tensorflow as tf\n",
    "\n",
    "from preprocess import MySimpleScaler\n",
    "\n",
    "iris = load_iris()\n",
    "scaler = MySimpleScaler()\n",
    "num_classes = len(iris.target_names)\n",
    "X = scaler.preprocess(iris.data)\n",
    "y = tf.keras.utils.to_categorical(iris.target, num_classes=num_classes)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(25, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(25, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax))\n",
    "model.compile(\n",
    "  optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=10, batch_size=1)\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "with open ('preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTPk8zy2r7N6"
   },
   "source": [
    "**Note:** When deploying a TensorFlow model to AI Platform without a custom container, you must export the trained model in the `SavedModel` format. When you deploy a custom container to AI Platform Predictions, you are able to export to the HDF5 format instead—or any other format that suits your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd"
   },
   "source": [
    "### Upload model artifacts and custom code to Cloud Storage\n",
    "\n",
    "Before you can deploy your model for serving, AI Platform needs access to the following files in Cloud Storage:\n",
    "\n",
    "* `model.h5` (model artifact)\n",
    "* `preprocessor.pkl` (model artifact)\n",
    "\n",
    "Run the following commands to upload your files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca67ee52d4d9",
    "outputId": "025ae8c9-7664-4d0a-e5c5-93c64f52f384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://model.h5 [Content-Type=application/x-hdf5]...\n",
      "Copying file://preprocessor.pkl [Content-Type=application/octet-stream]...      \n",
      "/ [2 files][ 42.1 KiB/ 42.1 KiB]                                                \n",
      "Operation completed over 2 objects/42.1 KiB.                                     \n",
      "/home/jupyter/cloud-aiplatform-demos/ucaip-notebooks/predictions\n"
     ]
    }
   ],
   "source": [
    "!gsutil cp model.h5 preprocessor.pkl {BUCKET_NAME}/{MODEL_ARTIFACT_DIR}/\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "480a1d88ecdb"
   },
   "source": [
    "## Build a HTTP Server with FastAPI\n",
    "\n",
    "Custom Container image [requires](https://cloud.google.com/ai-platform-unified/docs/predictions/custom-container-requirements#image) that the container must run an HTTP server. Specifically, the container must listen and respond to liveness checks, health checks, and prediction requests.\n",
    "\n",
    "In this tutorial, we will use FastAPI to implement the HTTP server. The HTTP server must listen for requests on 0.0.0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94af0ba5eadd",
    "outputId": "d17a2445-2b51-4067-93ba-9b098752eba7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/main.py\n",
    "from fastapi import FastAPI, Request\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from google.cloud import storage\n",
    "from preprocess import MySimpleScaler\n",
    "from sklearn.datasets import load_iris\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "gcs_client = storage.Client()\n",
    "\n",
    "with open(\"preprocessor.pkl\", 'wb') as preprocessor_f, open(\"model.h5\", 'wb') as model_f:\n",
    "    gcs_client.download_blob_to_file(\n",
    "        f\"{os.environ['AIP_STORAGE_URI']}/preprocessor.pkl\", preprocessor_f\n",
    "    )\n",
    "    gcs_client.download_blob_to_file(\n",
    "        f\"{os.environ['AIP_STORAGE_URI']}/model.h5\", model_f\n",
    "    )\n",
    "\n",
    "with open(\"preprocessor.pkl\", \"rb\") as f:\n",
    "    preprocessor = pickle.load(f)\n",
    "\n",
    "_class_names = load_iris().target_names\n",
    "_model = tf.keras.models.load_model(\"model.h5\")\n",
    "_preprocessor = preprocessor\n",
    "\n",
    "\n",
    "@app.get(os.environ['AIP_HEALTH_ROUTE'], status_code=200)\n",
    "def health():\n",
    "    \"\"\" health check to ensure HTTP server is ready to handle \n",
    "        prediction requests\n",
    "    \"\"\"\n",
    "    return {}\n",
    "\n",
    "\n",
    "@app.post(os.environ['AIP_PREDICT_ROUTE'])\n",
    "async def predict(request: Request):\n",
    "    body = await request.json()\n",
    "    print(body)\n",
    "\n",
    "    instances = body[\"instances\"]\n",
    "    inputs = np.asarray(instances)\n",
    "    preprocessed_inputs = _preprocessor.preprocess(inputs)\n",
    "    outputs = _model.predict(preprocessed_inputs)\n",
    "    print(outputs)\n",
    "\n",
    "    parameters = body.get(\"parameters\", {})\n",
    "    if parameters.get('probabilities'):\n",
    "      return outputs.tolist()\n",
    "    else:\n",
    "      return {\"predictions\": [_class_names[class_num] for class_num \n",
    "                              in np.argmax(outputs, axis=1)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ai-platform-2f444b6a-a742-444b-b91a-c7519f51bd77/custom-container-prediction-model\n"
     ]
    }
   ],
   "source": [
    "AIP_STORAGE_URI=f\"{BUCKET_NAME}/{MODEL_ARTIFACT_DIR}\"\n",
    "print(AIP_STORAGE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ai-platform-2f444b6a-a742-444b-b91a-c7519f51bd77/custom-container-prediction-model/model.h5\n",
      "gs://cloud-ai-platform-2f444b6a-a742-444b-b91a-c7519f51bd77/custom-container-prediction-model/preprocessor.pkl\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://cloud-ai-platform-2f444b6a-a742-444b-b91a-c7519f51bd77/custom-container-prediction-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!cd app & pwd & python -m uvicorn app.main:app --host 0.0.0.0 --port 80\n",
    "!!cd app/ ; \\\n",
    "export PROJECT_ID=$PROJECT_ID ; \\\n",
    "export AIP_HTTP_PORT=8080 ; \\\n",
    "export AIP_HEALTH_ROUTE=/health ; \\\n",
    "export AIP_PREDICT_ROUTE=/predict ; \\\n",
    "export AIP_STORAGE_URI={BUCKET_NAME}/{MODEL_ARTIFACT_DIR} ; \\\n",
    "python -m uvicorn main:app --host 0.0.0.0 --port 8082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl: (7) Failed to connect to 0.0.0.0 port 8082: Connection refused\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST \\\n",
    "-d @instances.json \\\n",
    "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "http://0.0.0.0:8082/predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUH8rSUe3DKj"
   },
   "source": [
    "Notice that, in addition to using the preprocessor that you defined during training, this predictor performs a postprocessing step that converts the neural network's softmax output (an array denoting the probability of each label being the correct one) into the label with the highest probability.\n",
    "\n",
    "However, if the predictor receives a `probabilities` keyword argument with the value `True`, it returns the probability array instead. The last part of this tutorial shows how to provide these additional parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "469f55daf250"
   },
   "source": [
    "### Add pre-start script\n",
    "FastAPI will execute this script before starting up the server. The `PORT` environment variable is set to equal `AIP_HTTP_PORT` in order to run FastAPI on same the port expected by AI Platform (Unified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69f438aca35b",
    "outputId": "3b6b15c7-de4d-4801-c855-9cff5f9bd44b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/prestart.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/prestart.sh\n",
    "#!/bin/bash\n",
    "export PORT=$AIP_HTTP_PORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b62ddf1def3"
   },
   "source": [
    "### Store test instances to use later\n",
    "To learn more about formatting input instances in JSON, [read the documentation.](https://cloud.google.com/ai-platform-unified/docs/predictions/online-predictions-custom-models#request-body-details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6605e9e6186",
    "outputId": "79be3c95-96ed-4b58-e074-8e820428fa6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting instances.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile instances.json\n",
    "{\n",
    "    \"instances\": [\n",
    "        [6.7, 3.1, 4.7, 1.5],\n",
    "        [4.6, 3.1, 1.5, 0.2]\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51e149fdec1b"
   },
   "source": [
    "## Build and push container to Artifact Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bdb9a7768a5"
   },
   "source": [
    "### Build your container\n",
    "Optionally copy in your credentials to run the container locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "fbb77f4f56c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: missing destination file operand after 'app/credentials.json'\n",
      "Try 'cp --help' for more information.\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Copy in credentials to run locally, this step can be skipped for deployment\n",
    "%cp $GOOGLE_APPLICATION_CREDENTIALS app/credentials.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "240578ec9efe"
   },
   "source": [
    "Write the Dockerfile, using `tiangolo/uvicorn-gunicorn-fastapi` as a base image. This will automatically run FastAPI for you using Gunicorn and Uvicorn. Visit [the FastAPI docs to read more about deploying FastAPI with Docker](https://fastapi.tiangolo.com/deployment/docker/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d3a6b9ed22b",
    "outputId": "b06cec6a-773c-498c-f113-27fda17aac3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.7\n",
    "\n",
    "COPY ./app /app\n",
    "COPY requirements.txt requirements.txt\n",
    "\n",
    "RUN pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR\u001b[0m:    Error loading ASGI app. Could not import module \"main\".\n"
     ]
    }
   ],
   "source": [
    "!python3 -m uvicorn main:app --host 0.0.0.0 --port 8082"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04c988201499"
   },
   "source": [
    "Build the image and tag the Artifact Registry path that you will push to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1e7d639b9cc",
    "outputId": "96ba0665-fdbc-440d-8220-6e58674b6146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 17 file(s) totalling 279.4 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://rthallam-demo-project_cloudbuild/source/1621294425.761263-9ba2b64277344b18926170ee69a0629a.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/rthallam-demo-project/locations/global/builds/af697d82-f26a-4616-8c4d-762e02252db4].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/af697d82-f26a-4616-8c4d-762e02252db4?project=560224572293].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"af697d82-f26a-4616-8c4d-762e02252db4\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://rthallam-demo-project_cloudbuild/source/1621294425.761263-9ba2b64277344b18926170ee69a0629a.tgz#1621294426163038\n",
      "Copying gs://rthallam-demo-project_cloudbuild/source/1621294425.761263-9ba2b64277344b18926170ee69a0629a.tgz#1621294426163038...\n",
      "/ [1 files][ 69.1 KiB/ 69.1 KiB]                                                \n",
      "Operation completed over 1 objects/69.1 KiB.                                     \n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  301.6kB\n",
      "Step 1/4 : FROM tiangolo/uvicorn-gunicorn-fastapi:python3.7\n",
      "python3.7: Pulling from tiangolo/uvicorn-gunicorn-fastapi\n",
      "90fe46dd8199: Pulling fs layer\n",
      "35a4f1977689: Pulling fs layer\n",
      "bbc37f14aded: Pulling fs layer\n",
      "74e27dc593d4: Pulling fs layer\n",
      "4352dcff7819: Pulling fs layer\n",
      "deb569b08de6: Pulling fs layer\n",
      "1aa33568be24: Pulling fs layer\n",
      "a8034acd5893: Pulling fs layer\n",
      "7dfa9b763153: Pulling fs layer\n",
      "a035e7b052a3: Pulling fs layer\n",
      "d4f2cd280496: Pulling fs layer\n",
      "e227f25dc86f: Pulling fs layer\n",
      "97a4044094b0: Pulling fs layer\n",
      "5d40afec4e92: Pulling fs layer\n",
      "f6b5e3636b46: Pulling fs layer\n",
      "85a8adaae1ef: Pulling fs layer\n",
      "3bd649e0d635: Pulling fs layer\n",
      "7855c9b64055: Pulling fs layer\n",
      "74e27dc593d4: Waiting\n",
      "4352dcff7819: Waiting\n",
      "deb569b08de6: Waiting\n",
      "1aa33568be24: Waiting\n",
      "a8034acd5893: Waiting\n",
      "7dfa9b763153: Waiting\n",
      "a035e7b052a3: Waiting\n",
      "d4f2cd280496: Waiting\n",
      "e227f25dc86f: Waiting\n",
      "97a4044094b0: Waiting\n",
      "5d40afec4e92: Waiting\n",
      "f6b5e3636b46: Waiting\n",
      "85a8adaae1ef: Waiting\n",
      "3bd649e0d635: Waiting\n",
      "7855c9b64055: Waiting\n",
      "35a4f1977689: Verifying Checksum\n",
      "35a4f1977689: Download complete\n",
      "bbc37f14aded: Verifying Checksum\n",
      "bbc37f14aded: Download complete\n",
      "74e27dc593d4: Verifying Checksum\n",
      "74e27dc593d4: Download complete\n",
      "90fe46dd8199: Verifying Checksum\n",
      "90fe46dd8199: Download complete\n",
      "deb569b08de6: Verifying Checksum\n",
      "deb569b08de6: Download complete\n",
      "a8034acd5893: Verifying Checksum\n",
      "a8034acd5893: Download complete\n",
      "7dfa9b763153: Verifying Checksum\n",
      "7dfa9b763153: Download complete\n",
      "1aa33568be24: Verifying Checksum\n",
      "1aa33568be24: Download complete\n",
      "d4f2cd280496: Verifying Checksum\n",
      "d4f2cd280496: Download complete\n",
      "a035e7b052a3: Verifying Checksum\n",
      "a035e7b052a3: Download complete\n",
      "97a4044094b0: Verifying Checksum\n",
      "97a4044094b0: Download complete\n",
      "e227f25dc86f: Verifying Checksum\n",
      "e227f25dc86f: Download complete\n",
      "5d40afec4e92: Verifying Checksum\n",
      "5d40afec4e92: Download complete\n",
      "f6b5e3636b46: Verifying Checksum\n",
      "f6b5e3636b46: Download complete\n",
      "85a8adaae1ef: Verifying Checksum\n",
      "85a8adaae1ef: Download complete\n",
      "3bd649e0d635: Verifying Checksum\n",
      "3bd649e0d635: Download complete\n",
      "7855c9b64055: Verifying Checksum\n",
      "7855c9b64055: Download complete\n",
      "4352dcff7819: Verifying Checksum\n",
      "4352dcff7819: Download complete\n",
      "90fe46dd8199: Pull complete\n",
      "35a4f1977689: Pull complete\n",
      "bbc37f14aded: Pull complete\n",
      "74e27dc593d4: Pull complete\n",
      "4352dcff7819: Pull complete\n",
      "deb569b08de6: Pull complete\n",
      "1aa33568be24: Pull complete\n",
      "a8034acd5893: Pull complete\n",
      "7dfa9b763153: Pull complete\n",
      "a035e7b052a3: Pull complete\n",
      "d4f2cd280496: Pull complete\n",
      "e227f25dc86f: Pull complete\n",
      "97a4044094b0: Pull complete\n",
      "5d40afec4e92: Pull complete\n",
      "f6b5e3636b46: Pull complete\n",
      "85a8adaae1ef: Pull complete\n",
      "3bd649e0d635: Pull complete\n",
      "7855c9b64055: Pull complete\n",
      "Digest: sha256:a0e0188a485fd8c232d8774ae4680d3b834f95dd2deccdb0211ce71cfd778b97\n",
      "Status: Downloaded newer image for tiangolo/uvicorn-gunicorn-fastapi:python3.7\n",
      " ---> e2f19ac0b4e3\n",
      "Step 2/4 : COPY ./app /app\n",
      " ---> 4c8bd52bbe73\n",
      "Step 3/4 : COPY requirements.txt requirements.txt\n",
      " ---> c37dd7f399d8\n",
      "Step 4/4 : RUN pip install -r requirements.txt\n",
      " ---> Running in dfb772db10fb\n",
      "Collecting joblib~=1.0\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting numpy~=1.20\n",
      "  Downloading numpy-1.20.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.3 MB)\n",
      "Collecting scikit-learn~=0.24\n",
      "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "Collecting tensorflow>=1.15\n",
      "  Downloading tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3 MB)\n",
      "Collecting google-cloud-storage<2.0.0dev,>=1.26.0\n",
      "  Downloading google_cloud_storage-1.38.0-py2.py3-none-any.whl (103 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting wheel~=0.35\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.17.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting google-auth<2.0dev,>=1.11.0\n",
      "  Downloading google_auth-1.30.0-py2.py3-none-any.whl (146 kB)\n",
      "Collecting google-resumable-media<2.0dev,>=1.2.0\n",
      "  Downloading google_resumable_media-1.2.0-py2.py3-none-any.whl (75 kB)\n",
      "Collecting requests<3.0.0dev,>=2.18.0\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting google-cloud-core<2.0dev,>=1.4.1\n",
      "  Downloading google_cloud_core-1.6.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting cached-property; python_version < \"3.8\"\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow>=1.15->-r requirements.txt (line 4)) (46.1.3)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"\n",
      "  Downloading google_crc32c-1.1.2-cp37-cp37m-manylinux2014_x86_64.whl (38 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "Collecting google-api-core<2.0.0dev,>=1.21.0\n",
      "  Downloading google_api_core-1.26.3-py2.py3-none-any.whl (93 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-4.0.1-py3-none-any.whl (16 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting cffi>=1.0.0\n",
      "  Downloading cffi-1.14.5-cp37-cp37m-manylinux1_x86_64.whl (402 kB)\n",
      "Collecting packaging>=14.3\n",
      "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "Collecting pytz\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Building wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=27ef5e5748217904f80b6a41570a49df7e810a9ab8e72f03bd1a073713c26be4\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=76423 sha256=884e6722cf7cf5a8714f44b6d4989957c5afb36c36b71e2cceb95d9973859de4\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
      "Successfully built termcolor wrapt\n",
      "\u001b[91mERROR: tensorflow 2.5.0 has requirement numpy~=1.19.2, but you'll have numpy 1.20.3 which is incompatible.\n",
      "\u001b[0mInstalling collected packages: joblib, numpy, threadpoolctl, scipy, scikit-learn, flatbuffers, opt-einsum, six, grpcio, termcolor, wrapt, typing-extensions, cached-property, h5py, tensorflow-estimator, keras-preprocessing, gast, wheel, protobuf, keras-nightly, absl-py, google-pasta, astunparse, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, tensorboard-data-server, tensorboard-plugin-wit, chardet, idna, certifi, urllib3, requests, oauthlib, requests-oauthlib, google-auth-oauthlib, zipp, importlib-metadata, markdown, werkzeug, tensorboard, tensorflow, pycparser, cffi, google-crc32c, google-resumable-media, pyparsing, packaging, pytz, googleapis-common-protos, google-api-core, google-cloud-core, google-cloud-storage\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "Successfully installed absl-py-0.12.0 astunparse-1.6.3 cached-property-1.5.2 cachetools-4.2.2 certifi-2020.12.5 cffi-1.14.5 chardet-4.0.0 flatbuffers-1.12 gast-0.4.0 google-api-core-1.26.3 google-auth-1.30.0 google-auth-oauthlib-0.4.4 google-cloud-core-1.6.0 google-cloud-storage-1.38.0 google-crc32c-1.1.2 google-pasta-0.2.0 google-resumable-media-1.2.0 googleapis-common-protos-1.53.0 grpcio-1.34.1 h5py-3.1.0 idna-2.10 importlib-metadata-4.0.1 joblib-1.0.1 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.20.3 oauthlib-3.1.0 opt-einsum-3.3.0 packaging-20.9 protobuf-3.17.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.20 pyparsing-2.4.7 pytz-2021.1 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.7.2 scikit-learn-0.24.2 scipy-1.6.3 six-1.15.0 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 threadpoolctl-2.1.0 typing-extensions-3.7.4.3 urllib3-1.26.4 werkzeug-2.0.1 wheel-0.36.2 wrapt-1.12.1 zipp-3.4.1\n",
      "\u001b[91mWARNING: You are using pip version 20.0.2; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container dfb772db10fb\n",
      " ---> ffd0fc996419\n",
      "Successfully built ffd0fc996419\n",
      "Successfully tagged us-central1-docker.pkg.dev/rthallam-demo-project/custom-container-prediction/keras-fastapi-server:latest\n",
      "PUSH\n",
      "Pushing us-central1-docker.pkg.dev/rthallam-demo-project/custom-container-prediction/keras-fastapi-server\n",
      "The push refers to repository [us-central1-docker.pkg.dev/rthallam-demo-project/custom-container-prediction/keras-fastapi-server]\n",
      "11ab3fdf702a: Preparing\n",
      "81d1304e1a93: Preparing\n",
      "71f431840a35: Preparing\n",
      "7f552331eddf: Preparing\n",
      "020fdd42a306: Preparing\n",
      "195d5e087746: Preparing\n",
      "9d89a89f95f7: Preparing\n",
      "b74e960321f5: Preparing\n",
      "a64fc8cc20a5: Preparing\n",
      "eac685a516c9: Preparing\n",
      "9018ab020550: Preparing\n",
      "2c065ea49213: Preparing\n",
      "956d28316107: Preparing\n",
      "86120ec29f78: Preparing\n",
      "5d34cecc2826: Preparing\n",
      "baf481fca4b7: Preparing\n",
      "3d3e92e98337: Preparing\n",
      "8967306e673e: Preparing\n",
      "9794a3b3ed45: Preparing\n",
      "5f77a51ade6a: Preparing\n",
      "e40d297cf5f8: Preparing\n",
      "195d5e087746: Waiting\n",
      "9d89a89f95f7: Waiting\n",
      "b74e960321f5: Waiting\n",
      "a64fc8cc20a5: Waiting\n",
      "eac685a516c9: Waiting\n",
      "9018ab020550: Waiting\n",
      "2c065ea49213: Waiting\n",
      "956d28316107: Waiting\n",
      "86120ec29f78: Waiting\n",
      "5d34cecc2826: Waiting\n",
      "baf481fca4b7: Waiting\n",
      "3d3e92e98337: Waiting\n",
      "8967306e673e: Waiting\n",
      "9794a3b3ed45: Waiting\n",
      "5f77a51ade6a: Waiting\n",
      "e40d297cf5f8: Waiting\n",
      "020fdd42a306: Layer already exists\n",
      "7f552331eddf: Layer already exists\n",
      "9d89a89f95f7: Layer already exists\n",
      "195d5e087746: Layer already exists\n",
      "b74e960321f5: Layer already exists\n",
      "a64fc8cc20a5: Layer already exists\n",
      "eac685a516c9: Layer already exists\n",
      "9018ab020550: Layer already exists\n",
      "2c065ea49213: Layer already exists\n",
      "956d28316107: Layer already exists\n",
      "81d1304e1a93: Pushed\n",
      "71f431840a35: Pushed\n",
      "86120ec29f78: Layer already exists\n",
      "5d34cecc2826: Layer already exists\n",
      "baf481fca4b7: Layer already exists\n",
      "3d3e92e98337: Layer already exists\n",
      "8967306e673e: Layer already exists\n",
      "9794a3b3ed45: Layer already exists\n",
      "e40d297cf5f8: Layer already exists\n",
      "5f77a51ade6a: Layer already exists\n",
      "11ab3fdf702a: Pushed\n",
      "latest: digest: sha256:fa37cc171f9ed4db534db5781cb97f4c9817e8f97efd9fcb6d46a0ad7483eed1 size: 4719\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                               IMAGES                                                                                                       STATUS\n",
      "af697d82-f26a-4616-8c4d-762e02252db4  2021-05-17T23:33:46+00:00  4M37S     gs://rthallam-demo-project_cloudbuild/source/1621294425.761263-9ba2b64277344b18926170ee69a0629a.tgz  us-central1-docker.pkg.dev/rthallam-demo-project/custom-container-prediction/keras-fastapi-server (+1 more)  SUCCESS\n",
      "\n",
      "\n",
      "To take a quick anonymous survey, run:\n",
      "  $ gcloud survey\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit \\\n",
    "    --tag={REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE} \\\n",
    "    ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "147a555f6c93"
   },
   "source": [
    "### Run and test the container locally (optional)\n",
    "\n",
    "Run the container locally in detached mode and provide the environment variables that the container requires. These env vars will be provided to the container by AI Platform Prediction once deployed. Test the `/health` and `/predict` routes, then stop the running image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following packages will be upgraded:\n",
      "  google-cloud-sdk-cloud-build-local\n",
      "1 upgraded, 0 newly installed, 0 to remove and 9 not upgraded.\n",
      "Need to get 2716 kB of archives.\n",
      "After this operation, 0 B of additional disk space will be used.\n",
      "Get:1 http://packages.cloud.google.com/apt cloud-sdk-buster/main amd64 google-cloud-sdk-cloud-build-local amd64 340.0.0-0 [2716 kB]\n",
      "Fetched 2716 kB in 0s (9428 kB/s)                          \n",
      "(Reading database ... 94091 files and directories currently installed.)\n",
      "Preparing to unpack .../google-cloud-sdk-cloud-build-local_340.0.0-0_amd64.deb ...\n",
      "Unpacking google-cloud-sdk-cloud-build-local (340.0.0-0) over (339.0.0-0) ...\n",
      "Setting up google-cloud-sdk-cloud-build-local (340.0.0-0) ...\n",
      "Processing triggers for google-cloud-sdk (338.0.0-0) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install google-cloud-sdk-cloud-build-local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021/05/18 18:34:57 Specify a source\n",
      "Usage: cloud-build-local --config=cloudbuild.yaml [--substitutions=_FOO=bar] [--dryrun=true/false] [--push=true/false] [--bind-mount-source=true/false] source\n"
     ]
    }
   ],
   "source": [
    "!cloud-build-local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021/05/18 18:44:55 RUNNER - [docker ps -a -q --filter name=step_[0-9]+|cloudbuild_|metadata]\n",
      "2021/05/18 18:44:55 RUNNER - [docker network ls -q --filter name=cloudbuild]\n",
      "2021/05/18 18:44:55 RUNNER - [docker volume ls -q --filter name=homevol|cloudbuild_]\n",
      "2021/05/18 18:44:55 Error loading config file: Unable to read config file: open cloudbuild.yaml: no such file or directory\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Run Container Locally\n",
    "!cloud-build-local {REGION}-docker.pkg.dev/{PROJECT_ID}/{ARTIFACT_REPO_NAME}/{CONTAINER_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "62ed2d334d0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local-iris\n",
      "eba5b0ee086a5e4e99ff352d7cc0fb34cf698d7c86f75b7c72e9784d904e7b39\n",
      "CONTAINER ID   IMAGE                                                                                               COMMAND                  CREATED                  STATUS                  PORTS                          NAMES\n",
      "eba5b0ee086a   us-central1-docker.pkg.dev/rthallam-demo-project/custom-container-prediction/keras-fastapi-server   \"/start.sh\"              Less than a second ago   Up Less than a second   80/tcp, 0.0.0.0:80->8082/tcp   local-iris\n",
      "78d095c72f9e   gcr.io/inverting-proxy/agent                                                                        \"/bin/sh -c '/opt/bi…\"   7 days ago               Up 7 days                                              proxy-agent\n",
      "curl: (56) Recv failure: Connection reset by peer\n",
      "curl: (52) Empty reply from server\n"
     ]
    }
   ],
   "source": [
    "!docker rm local-iris\n",
    "!docker run -d -p 80:8082 \\\n",
    "    --name=local-iris \\\n",
    "    -e AIP_HTTP_PORT=8082 \\\n",
    "    -e AIP_HEALTH_ROUTE=/health \\\n",
    "    -e AIP_PREDICT_ROUTE=/predict \\\n",
    "    -e AIP_STORAGE_URI={BUCKET_NAME}/{MODEL_ARTIFACT_DIR} \\\n",
    "    -e GOOGLE_APPLICATION_CREDENTIALS=credentials.json \\\n",
    "    {REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}\n",
    "!docker container ls\n",
    "!curl localhost:80/health\n",
    "!curl -X POST \\\n",
    "  -d @instances.json \\\n",
    "  -H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "  localhost/predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "ce629eea32fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl: (52) Empty reply from server\n"
     ]
    }
   ],
   "source": [
    "!curl localhost/health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                          COMMAND                  CREATED      STATUS      PORTS     NAMES\n",
      "78d095c72f9e   gcr.io/inverting-proxy/agent   \"/bin/sh -c '/opt/bi…\"   7 days ago   Up 7 days             proxy-agent\n"
     ]
    }
   ],
   "source": [
    "!docker container ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "56986f93438e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl: (7) Failed to connect to localhost port 8082: Connection refused\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST \\\n",
    "  -d @instances.json \\\n",
    "  -H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "  localhost:8082/predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a29fcbbe0188"
   },
   "outputs": [],
   "source": [
    "!docker stop local-iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "212b2935ea12"
   },
   "source": [
    "### Push the container to artifact registry\n",
    "\n",
    "Configure Docker to access Artifact Registry. Then push your container image to your Artifact Registry repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "09ffe2434e3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.beta.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta artifacts repositories create {REPOSITORY} \\\n",
    "    --repository-format=docker \\\n",
    "    --location=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "293437024749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "Docker configuration file updated.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "1dd7448f4703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [us-central1-docker.pkg.dev/rthallam-demo-project/custom-container-prediction/keras-fastapi-server]\n",
      "\n",
      "\u001b[1B8398e771: Preparing \n",
      "\u001b[1B37dcc776: Preparing \n",
      "\u001b[1B8c47e087: Preparing \n",
      "\u001b[1B2331eddf: Preparing \n",
      "\u001b[1Bdd42a306: Preparing \n",
      "\u001b[1B5e087746: Preparing \n",
      "\u001b[1Ba89f95f7: Preparing \n",
      "\u001b[1B960321f5: Preparing \n",
      "\u001b[1Bc8cc20a5: Preparing \n",
      "\u001b[1B85a516c9: Preparing \n",
      "\u001b[1Bab020550: Preparing \n",
      "\u001b[1B5ea49213: Preparing \n",
      "\u001b[1B28316107: Preparing \n",
      "\u001b[1B0ec29f78: Preparing \n",
      "\u001b[1Bcecc2826: Preparing \n",
      "\u001b[1B81fca4b7: Preparing \n",
      "\u001b[1B92e98337: Preparing \n",
      "\u001b[1B306e673e: Preparing \n",
      "\u001b[1Ba3b3ed45: Preparing \n",
      "\u001b[1Ba51ade6a: Preparing \n",
      "\u001b[21B398e771: Pushed   1.758GB/1.742GB\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[16A\u001b[2K\u001b[17A\u001b[2K\u001b[15A\u001b[2K\u001b[13A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2Klatest: digest: sha256:911a71412d6afa4aa2315eb159eb5a9cc623558fa0d6adc17b43f86a9b7dddf1 size: 4718\n"
     ]
    }
   ],
   "source": [
    "!docker push {REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 17 file(s) totalling 330.4 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://rthallam-demo-project_cloudbuild/source/1621364181.680066-ff30ae32becc4ec1ad59cb35feec8206.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/rthallam-demo-project/locations/global/builds/6a192cd6-8c4b-4d8a-8df5-dbba65e1e424].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/6a192cd6-8c4b-4d8a-8df5-dbba65e1e424?project=560224572293].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"6a192cd6-8c4b-4d8a-8df5-dbba65e1e424\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://rthallam-demo-project_cloudbuild/source/1621364181.680066-ff30ae32becc4ec1ad59cb35feec8206.tgz#1621364182048917\n",
      "Copying gs://rthallam-demo-project_cloudbuild/source/1621364181.680066-ff30ae32becc4ec1ad59cb35feec8206.tgz#1621364182048917...\n",
      "/ [1 files][ 75.1 KiB/ 75.1 KiB]                                                \n",
      "Operation completed over 1 objects/75.1 KiB.                                     \n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  354.3kB\n",
      "Step 1/4 : FROM tiangolo/uvicorn-gunicorn-fastapi:python3.7\n",
      "python3.7: Pulling from tiangolo/uvicorn-gunicorn-fastapi\n",
      "90fe46dd8199: Pulling fs layer\n",
      "35a4f1977689: Pulling fs layer\n",
      "bbc37f14aded: Pulling fs layer\n",
      "74e27dc593d4: Pulling fs layer\n",
      "4352dcff7819: Pulling fs layer\n",
      "deb569b08de6: Pulling fs layer\n",
      "74e27dc593d4: Waiting\n",
      "4352dcff7819: Waiting\n",
      "1aa33568be24: Pulling fs layer\n",
      "a8034acd5893: Pulling fs layer\n",
      "7dfa9b763153: Pulling fs layer\n",
      "a035e7b052a3: Pulling fs layer\n",
      "d4f2cd280496: Pulling fs layer\n",
      "deb569b08de6: Waiting\n",
      "1aa33568be24: Waiting\n",
      "a8034acd5893: Waiting\n",
      "7dfa9b763153: Waiting\n",
      "a035e7b052a3: Waiting\n",
      "e227f25dc86f: Pulling fs layer\n",
      "97a4044094b0: Pulling fs layer\n",
      "5d40afec4e92: Pulling fs layer\n",
      "f6b5e3636b46: Pulling fs layer\n",
      "85a8adaae1ef: Pulling fs layer\n",
      "d4f2cd280496: Waiting\n",
      "e227f25dc86f: Waiting\n",
      "97a4044094b0: Waiting\n",
      "5d40afec4e92: Waiting\n",
      "f6b5e3636b46: Waiting\n",
      "3bd649e0d635: Pulling fs layer\n",
      "85a8adaae1ef: Waiting\n",
      "3bd649e0d635: Waiting\n",
      "7855c9b64055: Pulling fs layer\n",
      "7855c9b64055: Waiting\n",
      "35a4f1977689: Verifying Checksum\n",
      "35a4f1977689: Download complete\n",
      "bbc37f14aded: Verifying Checksum\n",
      "bbc37f14aded: Download complete\n",
      "90fe46dd8199: Verifying Checksum\n",
      "90fe46dd8199: Download complete\n",
      "74e27dc593d4: Verifying Checksum\n",
      "74e27dc593d4: Download complete\n",
      "deb569b08de6: Verifying Checksum\n",
      "deb569b08de6: Download complete\n",
      "a8034acd5893: Verifying Checksum\n",
      "a8034acd5893: Download complete\n",
      "1aa33568be24: Verifying Checksum\n",
      "1aa33568be24: Download complete\n",
      "7dfa9b763153: Verifying Checksum\n",
      "7dfa9b763153: Download complete\n",
      "a035e7b052a3: Verifying Checksum\n",
      "a035e7b052a3: Download complete\n",
      "4352dcff7819: Verifying Checksum\n",
      "4352dcff7819: Download complete\n",
      "d4f2cd280496: Verifying Checksum\n",
      "d4f2cd280496: Download complete\n",
      "e227f25dc86f: Verifying Checksum\n",
      "e227f25dc86f: Download complete\n",
      "97a4044094b0: Verifying Checksum\n",
      "97a4044094b0: Download complete\n",
      "5d40afec4e92: Verifying Checksum\n",
      "5d40afec4e92: Download complete\n",
      "f6b5e3636b46: Verifying Checksum\n",
      "f6b5e3636b46: Download complete\n",
      "85a8adaae1ef: Download complete\n",
      "7855c9b64055: Verifying Checksum\n",
      "7855c9b64055: Download complete\n",
      "3bd649e0d635: Verifying Checksum\n",
      "3bd649e0d635: Download complete\n",
      "90fe46dd8199: Pull complete\n",
      "35a4f1977689: Pull complete\n",
      "bbc37f14aded: Pull complete\n",
      "74e27dc593d4: Pull complete\n",
      "4352dcff7819: Pull complete\n",
      "deb569b08de6: Pull complete\n",
      "1aa33568be24: Pull complete\n",
      "a8034acd5893: Pull complete\n",
      "7dfa9b763153: Pull complete\n",
      "a035e7b052a3: Pull complete\n",
      "d4f2cd280496: Pull complete\n",
      "e227f25dc86f: Pull complete\n",
      "97a4044094b0: Pull complete\n",
      "5d40afec4e92: Pull complete\n",
      "f6b5e3636b46: Pull complete\n",
      "85a8adaae1ef: Pull complete\n",
      "3bd649e0d635: Pull complete\n",
      "7855c9b64055: Pull complete\n",
      "Digest: sha256:a0e0188a485fd8c232d8774ae4680d3b834f95dd2deccdb0211ce71cfd778b97\n",
      "Status: Downloaded newer image for tiangolo/uvicorn-gunicorn-fastapi:python3.7\n",
      " ---> e2f19ac0b4e3\n",
      "Step 2/4 : COPY ./app /app\n",
      " ---> a43950252183\n",
      "Step 3/4 : COPY requirements.txt requirements.txt\n",
      " ---> 9ff7d778dca2\n",
      "Step 4/4 : RUN pip install -r requirements.txt\n",
      " ---> Running in 60250e515af5\n",
      "Collecting joblib~=1.0\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting numpy~=1.20\n",
      "  Downloading numpy-1.20.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.3 MB)\n",
      "Collecting scikit-learn~=0.24\n",
      "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "Collecting tensorflow>=1.15\n",
      "  Downloading tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3 MB)\n",
      "Collecting google-cloud-storage<2.0.0dev,>=1.26.0\n",
      "  Downloading google_cloud_storage-1.38.0-py2.py3-none-any.whl (103 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Collecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.17.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting wheel~=0.35\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting google-resumable-media<2.0dev,>=1.2.0\n",
      "  Downloading google_resumable_media-1.2.0-py2.py3-none-any.whl (75 kB)\n",
      "Collecting google-auth<2.0dev,>=1.11.0\n",
      "  Downloading google_auth-1.30.0-py2.py3-none-any.whl (146 kB)\n",
      "Collecting requests<3.0.0dev,>=2.18.0\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting google-cloud-core<2.0dev,>=1.4.1\n",
      "  Downloading google_cloud_core-1.6.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow>=1.15->-r requirements.txt (line 4)) (46.1.3)\n",
      "Collecting cached-property; python_version < \"3.8\"\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"\n",
      "  Downloading google_crc32c-1.1.2-cp37-cp37m-manylinux2014_x86_64.whl (38 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "Collecting google-api-core<2.0.0dev,>=1.21.0\n",
      "  Downloading google_api_core-1.27.0-py2.py3-none-any.whl (93 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-4.0.1-py3-none-any.whl (16 kB)\n",
      "Collecting cffi>=1.0.0\n",
      "  Downloading cffi-1.14.5-cp37-cp37m-manylinux1_x86_64.whl (402 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting packaging>=14.3\n",
      "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "Collecting pytz\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Building wheels for collected packages: wrapt, termcolor\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=76418 sha256=bd7b4557c6e32bce06d7e631e47d2d74a5d120ad62dc3487a0dd1d8bdac25e8a\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=d7503095ae6c72cf16c05ad5ac2f18cf4584c8ec76c31192cb9f9ad7d2ca5062\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built wrapt termcolor\n",
      "\u001b[91mERROR: tensorflow 2.5.0 has requirement numpy~=1.19.2, but you'll have numpy 1.20.3 which is incompatible.\n",
      "\u001b[0mInstalling collected packages: joblib, numpy, threadpoolctl, scipy, scikit-learn, six, absl-py, oauthlib, chardet, idna, urllib3, certifi, requests, requests-oauthlib, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, google-auth-oauthlib, tensorboard-data-server, werkzeug, zipp, typing-extensions, importlib-metadata, markdown, tensorboard-plugin-wit, grpcio, protobuf, wheel, tensorboard, keras-nightly, astunparse, opt-einsum, keras-preprocessing, google-pasta, flatbuffers, wrapt, tensorflow-estimator, cached-property, h5py, gast, termcolor, tensorflow, pycparser, cffi, google-crc32c, google-resumable-media, pyparsing, packaging, googleapis-common-protos, pytz, google-api-core, google-cloud-core, google-cloud-storage\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "Successfully installed absl-py-0.12.0 astunparse-1.6.3 cached-property-1.5.2 cachetools-4.2.2 certifi-2020.12.5 cffi-1.14.5 chardet-4.0.0 flatbuffers-1.12 gast-0.4.0 google-api-core-1.27.0 google-auth-1.30.0 google-auth-oauthlib-0.4.4 google-cloud-core-1.6.0 google-cloud-storage-1.38.0 google-crc32c-1.1.2 google-pasta-0.2.0 google-resumable-media-1.2.0 googleapis-common-protos-1.53.0 grpcio-1.34.1 h5py-3.1.0 idna-2.10 importlib-metadata-4.0.1 joblib-1.0.1 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.20.3 oauthlib-3.1.0 opt-einsum-3.3.0 packaging-20.9 protobuf-3.17.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.20 pyparsing-2.4.7 pytz-2021.1 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.7.2 scikit-learn-0.24.2 scipy-1.6.3 six-1.15.0 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 threadpoolctl-2.1.0 typing-extensions-3.7.4.3 urllib3-1.26.4 werkzeug-2.0.1 wheel-0.36.2 wrapt-1.12.1 zipp-3.4.1\n",
      "\u001b[91mWARNING: You are using pip version 20.0.2; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container 60250e515af5\n",
      " ---> e8ba47cf783b\n",
      "Successfully built e8ba47cf783b\n",
      "Successfully tagged us-central1-docker.pkg.dev/rthallam-demo-project/custom-container-prediction/keras-fastapi-server:latest\n",
      "PUSH\n",
      "Pushing us-central1-docker.pkg.dev/rthallam-demo-project/custom-container-prediction/keras-fastapi-server\n",
      "The push refers to repository [us-central1-docker.pkg.dev/rthallam-demo-project/custom-container-prediction/keras-fastapi-server]\n",
      "f7097dd62de0: Preparing\n",
      "8b9f2d2b98b8: Preparing\n",
      "abcf346865b2: Preparing\n",
      "7f552331eddf: Preparing\n",
      "020fdd42a306: Preparing\n",
      "195d5e087746: Preparing\n",
      "9d89a89f95f7: Preparing\n",
      "b74e960321f5: Preparing\n",
      "a64fc8cc20a5: Preparing\n",
      "eac685a516c9: Preparing\n",
      "9018ab020550: Preparing\n",
      "2c065ea49213: Preparing\n",
      "956d28316107: Preparing\n",
      "86120ec29f78: Preparing\n",
      "5d34cecc2826: Preparing\n",
      "baf481fca4b7: Preparing\n",
      "3d3e92e98337: Preparing\n",
      "8967306e673e: Preparing\n",
      "9794a3b3ed45: Preparing\n",
      "5f77a51ade6a: Preparing\n",
      "e40d297cf5f8: Preparing\n",
      "195d5e087746: Waiting\n",
      "9d89a89f95f7: Waiting\n",
      "b74e960321f5: Waiting\n",
      "a64fc8cc20a5: Waiting\n",
      "eac685a516c9: Waiting\n",
      "86120ec29f78: Waiting\n",
      "5d34cecc2826: Waiting\n",
      "baf481fca4b7: Waiting\n",
      "9018ab020550: Waiting\n",
      "2c065ea49213: Waiting\n",
      "3d3e92e98337: Waiting\n",
      "956d28316107: Waiting\n",
      "8967306e673e: Waiting\n",
      "9794a3b3ed45: Waiting\n",
      "5f77a51ade6a: Waiting\n",
      "e40d297cf5f8: Waiting\n",
      "020fdd42a306: Layer already exists\n",
      "7f552331eddf: Layer already exists\n",
      "195d5e087746: Layer already exists\n",
      "9d89a89f95f7: Layer already exists\n",
      "b74e960321f5: Layer already exists\n",
      "a64fc8cc20a5: Layer already exists\n",
      "eac685a516c9: Layer already exists\n",
      "9018ab020550: Layer already exists\n",
      "2c065ea49213: Layer already exists\n",
      "956d28316107: Layer already exists\n",
      "86120ec29f78: Layer already exists\n",
      "8b9f2d2b98b8: Pushed\n",
      "abcf346865b2: Pushed\n",
      "5d34cecc2826: Layer already exists\n",
      "3d3e92e98337: Layer already exists\n",
      "8967306e673e: Layer already exists\n",
      "9794a3b3ed45: Layer already exists\n",
      "baf481fca4b7: Layer already exists\n",
      "5f77a51ade6a: Layer already exists\n",
      "e40d297cf5f8: Layer already exists\n",
      "f7097dd62de0: Pushed\n",
      "latest: digest: sha256:a469c564491d6626c8e7c093c69d1d704a2444f9100b795147cfc2a2bbad6cbe size: 4719\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                               IMAGES                                                                                                       STATUS\n",
      "6a192cd6-8c4b-4d8a-8df5-dbba65e1e424  2021-05-18T18:56:22+00:00  4M34S     gs://rthallam-demo-project_cloudbuild/source/1621364181.680066-ff30ae32becc4ec1ad59cb35feec8206.tgz  us-central1-docker.pkg.dev/rthallam-demo-project/custom-container-prediction/keras-fastapi-server (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit \\\n",
    "    --tag={REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE} \\\n",
    "    ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b438bfa2129f"
   },
   "source": [
    "## Deploy to AI Platform (Unified)\n",
    "\n",
    "Use the [Python SDK for Cloud AI Platform](https://googleapis.dev/python/aiplatform/latest/index.html) to upload and deploy your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ae19df6a33e"
   },
   "source": [
    "### Upload the custom container model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "8d682d8388ec"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "574fb82d3eed"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "2738154345d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Model\n",
      "INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/560224572293/locations/us-central1/models/8226651552136298496/operations/6240103970849685504\n",
      "INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/560224572293/locations/us-central1/models/8226651552136298496\n",
      "INFO:google.cloud.aiplatform.models:To use this Model in another session:\n",
      "INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/560224572293/locations/us-central1/models/8226651552136298496')\n"
     ]
    }
   ],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    artifact_uri=f\"{BUCKET_NAME}/{MODEL_ARTIFACT_DIR}\",\n",
    "    serving_container_image_uri=f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd1b85afc7df"
   },
   "source": [
    "### Deploy the model on AI Platform (Unified)\n",
    "After this step completes, the model is deployed and ready for online prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "62cf66498a28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Endpoint\n",
      "INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/560224572293/locations/us-central1/endpoints/3799859409035722752/operations/8185659009873739776\n",
      "INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/560224572293/locations/us-central1/endpoints/3799859409035722752\n",
      "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n",
      "INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/560224572293/locations/us-central1/endpoints/3799859409035722752')\n",
      "INFO:google.cloud.aiplatform.models:Deploying model to Endpoint : projects/560224572293/locations/us-central1/endpoints/3799859409035722752\n",
      "INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/560224572293/locations/us-central1/endpoints/3799859409035722752/operations/109578978091597824\n",
      "INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/560224572293/locations/us-central1/endpoints/3799859409035722752\n"
     ]
    }
   ],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6883e7b07143"
   },
   "source": [
    "## Send predictions\n",
    "\n",
    "### Using Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "d69ed411c2d3"
   },
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "500 Internal Server Error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    922\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m--> 923\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"Internal Server Error\"\n\tdebug_error_string = \"{\"created\":\"@1621536930.078673731\",\"description\":\"Error received from peer ipv4:172.217.214.95:443\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1062,\"grpc_message\":\"Internal Server Error\",\"grpc_status\":13}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-a5c62c33784c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mendpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, instances, parameters)\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         prediction_response = self._prediction_client.predict(\n\u001b[0m\u001b[1;32m   1037\u001b[0m             \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrpc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;31m# Done; return the response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/ucaip-cc/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInternalServerError\u001b[0m: 500 Internal Server Error"
     ]
    }
   ],
   "source": [
    "endpoint.predict(instances=[[6.7, 3.1, 4.7, 1.5], [4.6, 3.1, 1.5, 0.2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arqz41gK7rWx"
   },
   "source": [
    "#### Sending prediction instances with additional parameters\n",
    "When you send a prediction request to a custom container, you can provide additional fields on your request body. The container's predict method receives these as fields of the `parameters` dictionary.\n",
    "\n",
    "The following code sends the same request as before, but this time it adds a probabilities field as an additional parameter to the request body:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6FtZQp9t7r5V"
   },
   "outputs": [],
   "source": [
    "endpoint.predict(instances=[[6.7, 3.1, 4.7, 1.5], [4.6, 3.1, 1.5, 0.2]], \n",
    "                 parameters={'probabilities': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "370d22f53427"
   },
   "source": [
    "### Using REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "ba55bc560d58"
   },
   "outputs": [],
   "source": [
    "ENDPOINT_ID = endpoint.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "95c562b4e98b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"error\": {\n",
      "    \"code\": 500,\n",
      "    \"message\": \"Internal Server Error\",\n",
      "    \"status\": \"INTERNAL\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! curl \\\n",
    "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d @instances.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{REGION}/endpoints/{ENDPOINT_ID}:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa71174a7dd0"
   },
   "source": [
    "### Using gcloud CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23b8e807b02c"
   },
   "outputs": [],
   "source": [
    "!gcloud beta ai endpoints predict $ENDPOINT_ID \\\n",
    "  --region=$REGION \\\n",
    "  --json-request=instances.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "Otherwise, you can delete the individual resources you created in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "# Undeploy model and delete endpoint\n",
    "endpoint.delete(force=True)\n",
    "\n",
    "# Delete the model resource\n",
    "model.delete()\n",
    "\n",
    "# Delete the container image from Artifact Registry\n",
    "!gcloud artifacts docker images delete \\\n",
    "    --quiet \\\n",
    "    --delete-tags \\\n",
    "    {REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AI_Platform_(Unified)_SDK_Custom_Container_Prediction_Keras.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python [conda env:ucaip-cc]",
   "language": "python",
   "name": "conda-env-ucaip-cc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
